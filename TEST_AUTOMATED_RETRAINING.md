# ğŸ§ª How to Test Automated Retraining

## Overview

The disaster detection pipeline currently has **two retraining mechanisms**:

1. **Manual Retraining** (via Google Colab)
2. **Drift-Triggered Retraining** (via Jenkins + Drift Detection)

This guide shows you how to test if both are working.

---

## âœ… Test 1: Check Current Retraining Setup

### **Step 1: Review Jenkinsfile Pipeline Stages**

```powershell
# View the Jenkins pipeline
cat Jenkinsfile
```

**What to look for:**
- Stage: `ğŸ“Š Check Model Performance` â†’ Validates model accuracy
- Stage: `ğŸ” Drift Detection` â†’ Checks for data drift
- Stage: `ğŸ³ Build Docker Image` â†’ Rebuilds if changes detected
- Stage: `ğŸš€ Deploy` â†’ Deploys updated model

**Current Status**: âœ… Pipeline has model validation

---

## ğŸ”„ Test 2: Trigger a Manual Retraining Test

### **Method A: Via Google Colab (Full Training)**

1. **Open the Training Notebook**
   ```
   Open: colab_notebooks/02_flood_model_training.ipynb
   ```

2. **Run all cells in sequence**
   - Cell 1: Setup & imports
   - Cell 2: Load Sentinel-1 SAR data from Earth Engine
   - Cell 3: Preprocess data
   - Cell 4: Build U-Net model
   - Cell 5: Train model
   - Cell 6: Evaluate and save

3. **Expected Output**
   ```
   Epoch 21/50: loss=0.15, val_loss=0.18
   âœ… Model training complete!
   ğŸ“Š Validation Accuracy: 96.71%
   ğŸ’¾ Model saved to: vizag_flood_model_TIMESTAMP.keras
   ```

4. **New Model Saved**
   - Location: `models/saved_models/flood/vizag_flood_model_YYYYMMDD_HHMMSS.keras`
   - Automatically synced to Google Drive

### **Method B: Via Jenkins Build (Deployment Only)**

1. **Trigger Jenkins Build**
   ```
   Visit: http://localhost:8080/job/disaster-detection-pipeline
   Click: "Build Now"
   ```

2. **Monitor Build Progress**
   - Check build console
   - Should complete in ~3-5 minutes

3. **Expected Stages**
   ```
   âœ… ğŸ” Checkout - Pull code from GitHub
   âœ… ğŸ§ª Environment - Verify Python
   âš ï¸ ğŸ“¥ Sync Models - Attempt Drive sync
   âœ… ğŸ³ Build Docker - Build new image
   âœ… ğŸš€ Deploy - Run container
   âœ… âœ… Health Check - Verify API
   ```

---

## ğŸ“Š Test 3: Verify Model Performance Tracking

### **Step 1: Check Model Metadata**

```powershell
# View model info via API
curl http://localhost:8000/models/info

# Expected response:
# {
#   "flood": {
#     "model_name": "vizag_flood_model_20251112_074534",
#     "version": "1.0",
#     "accuracy": 0.9671,
#     "iou": 0.4095,
#     "last_updated": "2025-11-12T14:13:58"
#   }
# }
```

### **Step 2: Check Model File Metadata**

```powershell
# List models by creation time (newest first)
Get-ChildItem C:\Docs\project\DevOps\models\saved_models\flood\ -Filter "*.keras" | Sort-Object LastWriteTime -Descending | Select-Object Name, LastWriteTime, Length

# Example output:
# vizag_flood_model_20251112_074534.keras (118 MB, latest)
# vizag_flood_model_20251111_123456.keras (116 MB, previous)
```

### **Step 3: Check Validation Metrics**

```powershell
# Look for metadata JSON file
Get-ChildItem C:\Docs\project\DevOps\models\saved_models\flood\ -Filter "*.json"

# View metadata
cat .\models\saved_models\flood\model_metadata_20251112_074534.json
```

---

## ğŸš¨ Test 4: Trigger Drift Detection (Optional)

### **Step 1: Create Baseline Data**

```powershell
# Create baseline from current model predictions
python scripts/create_baseline.py

# Expected output:
# âœ… Baseline created: data/baseline/
# âœ… Reference metrics saved
# ğŸ“Š Drift threshold: 0.5
```

### **Step 2: Simulate New Data**

```powershell
# Copy test imagery to data/retraining/ directory
# (This simulates new inference data collected in production)
cp test_images/*.tif data/retraining/
```

### **Step 3: Run Drift Monitor**

```powershell
# Check for drift in new data
python src/drift_detection/drift_monitor.py

# Expected output:
# ğŸ“Š Checking for drift...
# âœ… Drift Status: NO_DRIFT (score: 0.23)
# or
# âš ï¸ Drift Detected! (score: 0.67) â†’ Trigger Retrain
```

---

## ğŸ” Test 5: Verify Automated Retraining Trigger

### **Scenario: Drift Detected â†’ Auto-Retrain**

**Step 1: Manually Trigger Drift Alert**

```powershell
# Simulate drift detection by creating a trigger file
New-Item -Path "data/drift_alert.txt" -Value "drift_detected" -Force

# This would normally trigger Jenkins to retrain
```

**Step 2: Check Jenkins Logs**

```
Visit: http://localhost:8080/job/disaster-detection-pipeline
Look for: New build triggered by drift alert
```

**Step 3: Verify Model Updated**

```powershell
# Check if new model was created
Get-ChildItem C:\Docs\project\DevOps\models\saved_models\flood\ -Filter "*.keras" | Sort-Object LastWriteTime -Descending | Select-Object -First 1
```

---

## ğŸ“‹ Test Checklist

### **Quick Test (5 minutes)**

- [ ] Run: `curl http://localhost:8000/health` â†’ âœ… Responds
- [ ] Run: `curl http://localhost:8000/models/info` â†’ âœ… Shows model
- [ ] Visit: http://localhost:8080 â†’ âœ… Jenkins accessible
- [ ] Check: Latest build status â†’ âœ… Build #4 successful

### **Full Retraining Test (30 minutes)**

- [ ] Open Colab notebook: `02_flood_model_training.ipynb`
- [ ] Run all training cells
- [ ] Verify new model created in `models/saved_models/flood/`
- [ ] Check new model filename (should have new timestamp)
- [ ] Verify model synced to Google Drive

### **Drift Monitoring Test (optional)**

- [ ] Run: `python scripts/create_baseline.py`
- [ ] Check: `data/baseline/` directory created
- [ ] Run drift monitor: `python src/drift_detection/drift_monitor.py`
- [ ] Verify drift metrics logged

### **CI/CD Pipeline Test (5 minutes)**

- [ ] Visit: http://localhost:8080/job/disaster-detection-pipeline
- [ ] Click: "Build Now"
- [ ] Monitor: Build console output
- [ ] Verify: Build #N completes successfully
- [ ] Check: API still responding at http://localhost:8000/health

---

## ğŸ¯ Success Criteria

### **âœ… Automated Retraining IS Working If:**

1. **Model Validation Stage**
   - Jenkinsfile checks model accuracy âœ…
   - Build fails if accuracy drops below threshold âœ…

2. **Model Sync**
   - New trained models sync from Google Drive âœ…
   - Latest model is deployed âœ…

3. **Docker Deployment**
   - New model is copied into Docker image âœ…
   - API serves the latest model version âœ…

4. **Health Checks**
   - API health check passes after deployment âœ…
   - Model info endpoint shows current version âœ…

5. **Build Consistency**
   - Jenkins builds complete successfully âœ…
   - Build logs show all 9 stages executing âœ…

### **âŒ Issues to Watch For:**

- Build fails at "Sync Models from Drive" â†’ Credentials missing
- Build fails at "Environment Setup" â†’ Python not found
- Build fails at "Health Check" â†’ Previous container blocking port
- Model files not in Docker image â†’ Volume mount issue
- API returns wrong model version â†’ Cache not cleared

---

## ğŸ”§ Troubleshooting Retraining

### **Issue: Build Fails at Model Validation**

```powershell
# Check model metadata file exists
Test-Path .\models\saved_models\flood\model_metadata_*.json

# View model accuracy
cat .\models\saved_models\flood\model_metadata_*.json | findstr "accuracy"

# If missing, update Jenkinsfile to skip validation
```

### **Issue: Model Not Updating After Retraining**

```powershell
# Check if new model file was created
Get-ChildItem .\models\saved_models\flood\ -Filter "*.keras" | Sort-Object LastWriteTime -Descending | Select-Object -First 3

# If old model still being used, clear Docker cache
docker-compose down
docker image prune -f
docker-compose up -d detection-api
```

### **Issue: Drift Detection Not Triggering**

```powershell
# Verify baseline exists
Test-Path .\data\baseline\

# If not, create it
python scripts/create_baseline.py

# Check drift monitor script
cat src/drift_detection/drift_monitor.py
```

---

## ğŸ“Š Monitoring Commands

### **Check Current Model Info**

```powershell
# Via API
curl http://localhost:8000/models/info

# Via filesystem
$latestModel = Get-ChildItem .\models\saved_models\flood\ -Filter "*.keras" | Sort-Object LastWriteTime -Descending | Select-Object -First 1
Write-Host "Latest Model: $($latestModel.Name)"
Write-Host "Size: $($latestModel.Length) bytes"
Write-Host "Created: $($latestModel.LastWriteTime)"
```

### **Track Retraining History**

```powershell
# List all trained models by date
Get-ChildItem .\models\saved_models\flood\ -Filter "*.keras" | Sort-Object LastWriteTime -Descending | ForEach-Object {
    Write-Host "$($_.Name) - $($_.LastWriteTime)"
}
```

### **Monitor Jenkins Builds**

```powershell
# View build history
curl http://localhost:8080/job/disaster-detection-pipeline/api/json | ConvertFrom-Json | Select-Object -ExpandProperty builds | Select-Object number, result

# View specific build console
curl http://localhost:8080/job/disaster-detection-pipeline/4/consoleText
```

---

## ğŸ“ How Automated Retraining Works

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          AUTOMATED RETRAINING WORKFLOW              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                     â”‚
â”‚  1. Manual Training in Colab                       â”‚
â”‚     â””â”€ Train new model on fresh data               â”‚
â”‚     â””â”€ Save to models/saved_models/flood/          â”‚
â”‚     â””â”€ Sync to Google Drive                        â”‚
â”‚                                                     â”‚
â”‚  2. GitHub Push Trigger                            â”‚
â”‚     â””â”€ Commit code changes                         â”‚
â”‚     â””â”€ Push to main branch                         â”‚
â”‚     â””â”€ Webhook notifies Jenkins                    â”‚
â”‚                                                     â”‚
â”‚  3. Jenkins Pipeline Execution                     â”‚
â”‚     â””â”€ Checkout latest code                        â”‚
â”‚     â””â”€ Sync latest models from Drive               â”‚
â”‚     â””â”€ Validate model performance                  â”‚
â”‚     â””â”€ Check for data drift                        â”‚
â”‚     â””â”€ Build Docker image with new model           â”‚
â”‚     â””â”€ Deploy to http://localhost:8000             â”‚
â”‚     â””â”€ Health check API endpoints                  â”‚
â”‚                                                     â”‚
â”‚  4. API Live with New Model                        â”‚
â”‚     â””â”€ Predictions use latest trained model        â”‚
â”‚     â””â”€ Metrics logged for drift monitoring         â”‚
â”‚                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Test Report Template

Use this to document your retraining tests:

```
TEST: Automated Retraining Verification
DATE: __________
TESTER: __________

1. Model Validation
   - Jenkinsfile checks accuracy? [YES/NO]
   - Current model accuracy: _____%
   - Threshold: 85%
   - Status: [PASS/FAIL]

2. Model Deployment
   - New model deployed? [YES/NO]
   - API returns latest model? [YES/NO]
   - Build time: _____ minutes
   - Status: [PASS/FAIL]

3. Drift Monitoring
   - Baseline created? [YES/NO]
   - Drift detector working? [YES/NO]
   - Status: [PASS/FAIL]

OVERALL: [âœ… WORKING / âš ï¸ PARTIAL / âŒ BROKEN]

Notes:
_______________________________________________________
_______________________________________________________
```

---

## ğŸš€ Summary

**To test if automated retraining is working:**

1. **Quick Check** (5 min):
   - Visit Jenkins: http://localhost:8080
   - Click "Build Now" on pipeline
   - Verify all stages complete âœ…

2. **Full Test** (30 min):
   - Run Colab training notebook
   - Trigger Jenkins build
   - Verify new model deployed
   - Test API with curl

3. **Monitor** (Ongoing):
   - Check build history
   - Track model versions
   - Monitor drift metrics

---

**Status**: âœ… **Ready to Test**

Next: Run the quick check and let me know results! ğŸ¯
