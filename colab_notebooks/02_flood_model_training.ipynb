{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5faf2888",
   "metadata": {},
   "source": [
    "# Flood Detection Model Training\n",
    "## Using SAR Sentinel-1 Data from Google Earth Engine\n",
    "\n",
    "This notebook trains a U-Net model for flood segmentation using free GPU on Google Colab.\n",
    "\n",
    "**Requirements:**\n",
    "- Run in Google Colab (free GPU tier)\n",
    "- Google Drive mounted\n",
    "- Earth Engine authenticated\n",
    "\n",
    "**Output:**\n",
    "- Trained model saved to Drive\n",
    "- Training metrics and visualizations\n",
    "- Baseline features for drift detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0a06af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Setup Colab Environment\n",
    "print(\"üöÄ Setting up Colab environment for Flood Model Training\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Add utils to path\n",
    "import sys\n",
    "sys.path.append('/content/drive/MyDrive/disaster_detection/notebooks/utils')\n",
    "\n",
    "# Import helpers\n",
    "from colab_helpers import (\n",
    "    setup_colab_environment,\n",
    "    get_drive_paths,\n",
    "    ensure_drive_directories,\n",
    "    save_model_to_drive,\n",
    "    plot_training_history\n",
    ")\n",
    "\n",
    "# Run setup\n",
    "setup_colab_environment()\n",
    "ensure_drive_directories()\n",
    "\n",
    "# Import standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "# TensorFlow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "# Earth Engine\n",
    "import ee\n",
    "import geemap\n",
    "\n",
    "print(f\"\\n‚úÖ TensorFlow version: {tf.__version__}\")\n",
    "print(f\"‚úÖ GPU Available: {tf.config.list_physical_devices('GPU')}\")\n",
    "print(f\"‚úÖ Earth Engine initialized\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f152d8",
   "metadata": {},
   "source": [
    "## Step 1: Define Area of Interest and Download SAR Data\n",
    "\n",
    "We'll use Sentinel-1 SAR data which is excellent for flood detection because:\n",
    "- Works day/night and through clouds\n",
    "- VV and VH polarizations detect water surfaces\n",
    "- Free access via Google Earth Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fe8a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Download SAR Training Data\n",
    "print(\"üì• Downloading SAR training data from Google Earth Engine...\")\n",
    "\n",
    "# Define AOI (example: Mumbai flood-prone region)\n",
    "aoi = ee.Geometry.Rectangle([72.7, 18.9, 73.0, 19.3])\n",
    "\n",
    "# Visualization\n",
    "Map = geemap.Map()\n",
    "Map.centerObject(aoi, zoom=10)\n",
    "Map.addLayer(aoi, {'color': 'red'}, 'Area of Interest')\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232f0013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Download Function\n",
    "def download_sar_images(aoi, start_date, end_date, max_images=50):\n",
    "    \"\"\"\n",
    "    Download Sentinel-1 SAR imagery for flood detection\n",
    "    \"\"\"\n",
    "    paths = get_drive_paths()\n",
    "    save_dir = f\"{paths['data']}/sar_training\"\n",
    "    \n",
    "    # Query Sentinel-1 collection\n",
    "    s1_collection = (ee.ImageCollection('COPERNICUS/S1_GRD')\n",
    "        .filterBounds(aoi)\n",
    "        .filterDate(start_date, end_date)\n",
    "        .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV'))\n",
    "        .filter(ee.Filter.eq('instrumentMode', 'IW'))\n",
    "        .select(['VV', 'VH']))\n",
    "    \n",
    "    count = s1_collection.size().getInfo()\n",
    "    print(f\"Found {count} SAR images\")\n",
    "    \n",
    "    # Download images (limited to max_images)\n",
    "    image_list = s1_collection.toList(min(count, max_images))\n",
    "    \n",
    "    for i in range(min(count, max_images)):\n",
    "        try:\n",
    "            image = ee.Image(image_list.get(i))\n",
    "            \n",
    "            # Calculate flood index (VV/VH ratio)\n",
    "            flood_index = image.select('VV').divide(image.select('VH')).rename('flood_index')\n",
    "            image_with_index = image.addBands(flood_index)\n",
    "            \n",
    "            # Export (simplified - in production use geemap.ee_export_image)\n",
    "            print(f\"  Processing image {i+1}/{min(count, max_images)}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  Error processing image {i}: {e}\")\n",
    "    \n",
    "    print(f\"‚úÖ Downloaded {min(count, max_images)} images to {save_dir}\")\n",
    "\n",
    "# Run download\n",
    "download_sar_images(aoi, '2023-01-01', '2024-12-31', max_images=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7992fca4",
   "metadata": {},
   "source": [
    "## Step 2: Build U-Net Model\n",
    "\n",
    "U-Net is ideal for image segmentation tasks like flood detection:\n",
    "- Encoder-decoder architecture\n",
    "- Skip connections preserve spatial information\n",
    "- Works well with limited training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde2a291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Build U-Net Model\n",
    "def build_unet_flood_model(input_shape=(256, 256, 3)):\n",
    "    \"\"\"\n",
    "    Build U-Net architecture for flood segmentation\n",
    "    Input: 3 channels (VV, VH, flood_index)\n",
    "    Output: Binary flood mask\n",
    "    \"\"\"\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # Encoder (downsampling)\n",
    "    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n",
    "    p1 = layers.MaxPooling2D((2, 2))(c1)\n",
    "    \n",
    "    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
    "    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n",
    "    p2 = layers.MaxPooling2D((2, 2))(c2)\n",
    "    \n",
    "    c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
    "    c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c3)\n",
    "    p3 = layers.MaxPooling2D((2, 2))(c3)\n",
    "    \n",
    "    # Bottleneck\n",
    "    c4 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(p3)\n",
    "    c4 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(c4)\n",
    "    \n",
    "    # Decoder (upsampling)\n",
    "    u5 = layers.UpSampling2D((2, 2))(c4)\n",
    "    u5 = layers.concatenate([u5, c3])\n",
    "    c5 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(u5)\n",
    "    c5 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c5)\n",
    "    \n",
    "    u6 = layers.UpSampling2D((2, 2))(c5)\n",
    "    u6 = layers.concatenate([u6, c2])\n",
    "    c6 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(u6)\n",
    "    c6 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c6)\n",
    "    \n",
    "    u7 = layers.UpSampling2D((2, 2))(c6)\n",
    "    u7 = layers.concatenate([u7, c1])\n",
    "    c7 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u7)\n",
    "    c7 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c7)\n",
    "    \n",
    "    # Output layer\n",
    "    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(c7)\n",
    "    \n",
    "    model = models.Model(inputs=[inputs], outputs=[outputs])\n",
    "    \n",
    "    # Compile\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', tf.keras.metrics.MeanIoU(num_classes=2)]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Build model\n",
    "model = build_unet_flood_model()\n",
    "print(\"‚úÖ U-Net model created\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac905c2c",
   "metadata": {},
   "source": [
    "## Step 3: Train Model\n",
    "\n",
    "Training on Colab's free GPU (usually Tesla T4 or P100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28af79a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Training\n",
    "print(\"üî• Starting model training...\")\n",
    "\n",
    "# Setup callbacks\n",
    "paths = get_drive_paths()\n",
    "checkpoint_path = f\"{paths['models']}/flood/checkpoints/model_{{epoch:02d}}_{{val_loss:.4f}}.h5\"\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=10, restore_best_weights=True, verbose=1),\n",
    "    ModelCheckpoint(checkpoint_path, save_best_only=True, monitor='val_loss', verbose=1),\n",
    "    ReduceLROnPlateau(factor=0.5, patience=5, verbose=1)\n",
    "]\n",
    "\n",
    "# Note: In production, load actual data here\n",
    "# For this scaffold, we'll create dummy data\n",
    "print(\"‚ö†Ô∏è  Using dummy data for demonstration\")\n",
    "X_train = np.random.randn(20, 256, 256, 3)\n",
    "y_train = np.random.randint(0, 2, (20, 256, 256, 1)).astype(np.float32)\n",
    "X_val = np.random.randn(5, 256, 256, 3)\n",
    "y_val = np.random.randint(0, 2, (5, 256, 256, 1)).astype(np.float32)\n",
    "\n",
    "# Train\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=3,  # Use 50+ in production\n",
    "    batch_size=4,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da094b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Evaluate and Save\n",
    "val_loss, val_acc, val_iou = model.evaluate(X_val, y_val)\n",
    "\n",
    "print(f\"\\nüìä Validation Metrics:\")\n",
    "print(f\"   Loss: {val_loss:.4f}\")\n",
    "print(f\"   Accuracy: {val_acc:.4f}\")\n",
    "print(f\"   IoU: {val_iou:.4f}\")\n",
    "\n",
    "# Save model\n",
    "model_name = f\"flood_model_{datetime.now().strftime('%Y%m%d_%H%M%S')}.h5\"\n",
    "model_path = save_model_to_drive(model, model_name, 'flood')\n",
    "\n",
    "# Save metrics\n",
    "import json\n",
    "metrics = {\n",
    "    'model_type': 'flood_detection',\n",
    "    'architecture': 'unet',\n",
    "    'training_date': datetime.now().isoformat(),\n",
    "    'val_loss': float(val_loss),\n",
    "    'val_accuracy': float(val_acc),\n",
    "    'val_iou': float(val_iou),\n",
    "    'epochs_trained': len(history.history['loss'])\n",
    "}\n",
    "\n",
    "from colab_helpers import save_metrics_to_drive\n",
    "save_metrics_to_drive(metrics, model_path)\n",
    "\n",
    "print(f\"\\n‚úÖ Model and metrics saved!\")\n",
    "print(f\"   Model: {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdf86f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Create Baseline for Drift Detection\n",
    "print(\"üìä Creating baseline features for drift detection...\")\n",
    "\n",
    "def extract_baseline_features(X_data):\n",
    "    \"\"\"Extract features for drift monitoring\"\"\"\n",
    "    features = {\n",
    "        'mean_intensity': [],\n",
    "        'std_intensity': [],\n",
    "        'vv_mean': [],\n",
    "        'vh_mean': [],\n",
    "        'flood_index_mean': []\n",
    "    }\n",
    "    \n",
    "    for img in X_data:\n",
    "        features['mean_intensity'].append(np.mean(img))\n",
    "        features['std_intensity'].append(np.std(img))\n",
    "        features['vv_mean'].append(np.mean(img[:, :, 0]))\n",
    "        features['vh_mean'].append(np.mean(img[:, :, 1]))\n",
    "        features['flood_index_mean'].append(np.mean(img[:, :, 2]))\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Extract from validation set\n",
    "baseline_features = extract_baseline_features(X_val)\n",
    "\n",
    "# Save\n",
    "baseline_df = pd.DataFrame(baseline_features)\n",
    "paths = get_drive_paths()\n",
    "baseline_path = f\"{paths['baseline']}/flood_baseline_features.csv\"\n",
    "baseline_df.to_csv(baseline_path, index=False)\n",
    "\n",
    "print(f\"‚úÖ Baseline saved to: {baseline_path}\")\n",
    "print(f\"\\nüìà Baseline Statistics:\")\n",
    "print(baseline_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba28c56",
   "metadata": {},
   "source": [
    "## ‚úÖ Training Complete!\n",
    "\n",
    "Next steps:\n",
    "1. Download this model to local server via Jenkins\n",
    "2. Deploy in FastAPI inference server\n",
    "3. Monitor for drift in production\n",
    "4. Auto-retrain when drift detected\n",
    "\n",
    "**Note:** Upload this notebook to your Google Drive and note its file ID for the Jenkins pipeline."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
